{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gZN0oQGiclf",
        "outputId": "1a0f1917-8c7e-490a-8100-caf676a3fe3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action for Agent 1: 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SwarmAgent:\n",
        "    def __init__(self, agent_id, position):\n",
        "        self.agent_id = agent_id\n",
        "        self.position = position\n",
        "\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class SwarmController:\n",
        "    def __init__(self, num_agents, environment_size, hidden_size, learning_rate):\n",
        "        self.num_agents = num_agents\n",
        "        self.environment_size = environment_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.model = FeedforwardNN(environment_size[0]*environment_size[1], hidden_size, num_agents)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(self, agent_data, labels, num_epochs):\n",
        "        agent_data_tensor = torch.tensor(agent_data, dtype=torch.float)\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(agent_data_tensor)\n",
        "            loss = self.criterion(outputs, labels_tensor)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def get_action(self, agent):\n",
        "        state = np.zeros(self.environment_size)\n",
        "        state[tuple(agent.position)] = 1\n",
        "        state_tensor = torch.tensor(state.flatten(), dtype=torch.float).unsqueeze(0)\n",
        "        outputs = self.model(state_tensor)\n",
        "        action = torch.argmax(outputs).item()\n",
        "        return action\n",
        "\n",
        "# Usage example\n",
        "num_agents = 10\n",
        "environment_size = (10, 10)\n",
        "hidden_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "swarm_agents = []\n",
        "for i in range(num_agents):\n",
        "    position = np.random.randint(0, environment_size[0]), np.random.randint(0, environment_size[1])\n",
        "    agent = SwarmAgent(i, position)\n",
        "    swarm_agents.append(agent)\n",
        "\n",
        "agent_data = [np.random.rand(environment_size[0]*environment_size[1]) for _ in range(num_agents)]\n",
        "labels = np.random.randint(0, num_agents, size=num_agents)\n",
        "\n",
        "swarm_controller = SwarmController(num_agents, environment_size, hidden_size, learning_rate)\n",
        "swarm_controller.train(agent_data, labels, num_epochs=100)\n",
        "\n",
        "# Get action for a specific agent\n",
        "agent_id = 1\n",
        "action = swarm_controller.get_action(swarm_agents[agent_id])\n",
        "print(f\"Action for Agent {agent_id}: {action}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SwarmAgent class represents an agent in the swarm, holding an agent ID and a position in the environment.\n",
        "\n",
        "The FeedforwardNN class defines a feedforward neural network model. It consists of two fully connected layers with a ReLU activation function in between.\n",
        "\n",
        "The SwarmController class represents the controller that uses the feedforward neural network for decision-making. It takes the number of agents, environment size, hidden layer size, and learning rate as input.\n",
        "\n",
        "The SwarmController initializes a FeedforwardNN model with the specified input size, hidden size, and output size (number of agents). It also defines the criterion (cross-entropy loss) and optimizer (Adam optimizer).\n",
        "\n",
        "The train method trains the model using the provided agent data and labels. It iterates over the specified number of epochs, calculates the loss, and updates the model's parameters.\n",
        "\n",
        "The get_action method takes an agent as input and uses the model to predict the action for that agent based on its position in the environment.\n",
        "\n",
        "In the usage example, a swarm of agents is created with random positions in the environment.\n",
        "\n",
        "Random agent data and labels are generated for training the model.\n",
        "\n",
        "An instance of SwarmController is created, passing the necessary parameters.\n",
        "\n",
        "The train method is called to train the model using the agent data and labels.\n",
        "\n",
        "The get_action method is called to retrieve the action for a specific agent.\n",
        "\n",
        "The action for the agent is printed.\n",
        "\n",
        "In summary, the code demonstrates the usage of a feedforward neural network model as a swarm controller. It trains the model using agent data and labels, allowing the model to predict actions for the swarm agents based on their positions in the environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "sVesX9ADkOhL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbKg9bmIk-CX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}