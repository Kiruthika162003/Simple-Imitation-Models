{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SwarmAgent:\n",
        "    def __init__(self, agent_id, position):\n",
        "        self.agent_id = agent_id\n",
        "        self.position = position\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class ClassicalIL:\n",
        "    def __init__(self, num_agents, environment_size, num_epochs, learning_rate):\n",
        "        self.num_agents = num_agents\n",
        "        self.environment_size = environment_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.classifier = Classifier(environment_size[0] * environment_size[1], num_agents)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "    def train(self, expert_trajectories, expert_actions):\n",
        "        states, actions = self.convert_expert_data(expert_trajectories, expert_actions)\n",
        "\n",
        "        states = torch.tensor(states, dtype=torch.float)\n",
        "        actions = torch.tensor(actions, dtype=torch.long)\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            logits = self.classifier(states)\n",
        "            loss = self.criterion(logits, actions)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def convert_expert_data(self, expert_trajectories, expert_actions):\n",
        "        states = []\n",
        "        actions = []\n",
        "\n",
        "        for trajectory, action_sequence in zip(expert_trajectories, expert_actions):\n",
        "            for agent, action in zip(trajectory, action_sequence):\n",
        "                state = np.zeros(self.environment_size)\n",
        "                state[tuple(agent.position)] = 1\n",
        "                states.append(state.flatten())\n",
        "                actions.append(agent.agent_id)\n",
        "\n",
        "        return states, actions\n",
        "\n",
        "    def get_action(self, agent):\n",
        "        state = np.zeros(self.environment_size)\n",
        "        state[tuple(agent.position)] = 1\n",
        "        state = torch.tensor(state.flatten(), dtype=torch.float).unsqueeze(0)\n",
        "        logits = self.classifier(state)\n",
        "        action = torch.argmax(logits).item()\n",
        "        return action\n",
        "\n",
        "# Usage example\n",
        "num_agents = 10\n",
        "environment_size = (10, 10)\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "swarm_agents = []\n",
        "for i in range(num_agents):\n",
        "    position = np.random.randint(0, environment_size[0]), np.random.randint(0, environment_size[1])\n",
        "    agent = SwarmAgent(i, position)\n",
        "    swarm_agents.append(agent)\n",
        "\n",
        "expert_trajectories = [swarm_agents]  # List of expert agent trajectories\n",
        "expert_actions = [np.random.randint(0, num_agents, size=num_agents)]  # List of expert actions corresponding to each agent\n",
        "\n",
        "cil = ClassicalIL(num_agents, environment_size, num_epochs, learning_rate)\n",
        "cil.train(expert_trajectories, expert_actions)\n",
        "\n",
        "# Get action for a specific agent\n",
        "agent_id = 0\n",
        "action = cil.get_action(swarm_agents[agent_id])\n",
        "print(f\"Action for Agent {agent_id}: {action}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevIMtAggpEY",
        "outputId": "0c0c3417-fe10-4083-dda4-68a9e233f9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ff0935484601>:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  states = torch.tensor(states, dtype=torch.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action for Agent 0: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a SwarmAgent class that represents an agent in the swarm. Each agent has an agent ID and a position in the environment.\n",
        "\n",
        "The Classifier class is a neural network model that consists of two fully connected layers with a ReLU activation function. It takes the input size and the number of output classes as parameters.\n",
        "\n",
        "The ClassicalIL class represents the Classical Imitation Learning algorithm. It takes the number of agents, environment size, number of epochs, and learning rate as input.\n",
        "\n",
        "The ClassicalIL class contains a classifier model, a loss criterion (CrossEntropyLoss), and an optimizer (Adam optimizer).\n",
        "\n",
        "The train method trains the classifier model using expert trajectories and expert actions. It iterates for the specified number of epochs.\n",
        "\n",
        "The convert_expert_data method converts the expert trajectories and actions into a list of states and actions. Each state is represented as a flattened array, where the position of the agent is set to 1. The agent's ID is used as the corresponding action.\n",
        "\n",
        "The get_action method retrieves the action for a specific agent based on its position. It constructs a state representation by creating an environment-sized array and setting the position of the agent to 1. The state is then converted to a tensor and passed through the classifier model. The action with the highest logit value is extracted using torch.argmax.\n",
        "\n",
        "In the usage example, a swarm of agents is created with random positions in the environment.\n",
        "\n",
        "Expert trajectories are defined as a list containing agent trajectories, and expert actions are defined as a list of action sequences corresponding to each agent.\n",
        "\n",
        "An instance of ClassicalIL is created, passing the necessary parameters.\n",
        "\n",
        "The train method is called to train the classifier model using the expert trajectories and actions.\n",
        "\n",
        "The get_action method is called to retrieve the action for a specific agent.\n",
        "\n",
        "The action for the agent is printed.\n",
        "\n",
        "In summary, the code implements Classical Imitation Learning (CIL) in swarm robotics. It trains a neural network classifier to imitate expert behavior based on the agents' positions in the environment. The trained classifier can then be used to select actions for the swarm agents."
      ],
      "metadata": {
        "id": "PW3gjgLGic3o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tj0BUG2ciCtf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}